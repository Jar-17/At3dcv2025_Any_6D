# Any6D: Model-free 6D Pose Estimation of Novel Objects

This is the official implementation of our paper accepted by CVPR 2025 

[[Website]](https://sites.google.com/view/taeyeop-lee/any6d) [[Paper]](https://arxiv.org/pdf/2503.18673)

Authors: Taeyeop Lee, Bowen Wen, Minjun Kang, Gyuree Kang, In So Kweon, Kuk-Jin Yoon

<p align="center">
  <img src="./teaser/robot.gif" width="600"/>
</p>

# Abstract

We introduce Any6D, a model-free framework for 6D object pose estimation that requires only a single RGB-D anchor image to estimate both the 6D pose and size of unknown objects in novel scenes. Unlike existing methods that rely on textured 3D models or multiple viewpoints, Any6D leverages a joint object alignment process to enhance 2D-3D alignment and metric scale estimation for improved pose accuracy. Our approach integrates a render-and-compare strategy to generate and refine pose hypotheses, enabling robust performance in scenarios with occlusions, non-overlapping views, diverse lighting conditions, and large cross-environment variations. We evaluate our method on five challenging datasets: REAL275, Toyota-Light, HO3D, YCBINEOAT, and LM-O, demonstrating its effectiveness in significantly outperforming state-of-the-art methods for novel object pose estimation.


<p align="center">
  <img src="./teaser/teaser.png" width="800"/>
</p>



# Coming Soon (March ~ May 2025)
